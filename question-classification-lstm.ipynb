{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735697e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-13T10:45:03.744643Z",
     "iopub.status.busy": "2026-02-13T10:45:03.744165Z",
     "iopub.status.idle": "2026-02-13T10:45:05.109936Z",
     "shell.execute_reply": "2026-02-13T10:45:05.108636Z"
    },
    "papermill": {
     "duration": 1.373375,
     "end_time": "2026-02-13T10:45:05.112297",
     "exception": false,
     "start_time": "2026-02-13T10:45:03.738922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets/aabdollahii/university-questions/train.json\n",
      "/kaggle/input/datasets/aabdollahii/university-questions/test.json\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/spacy_loggers-1.0.5-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/cymem-2.0.13-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/__script__.py\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/shellingham-1.5.4-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/setuptools-82.0.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/huggingface_hub-0.34.6-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/typing_extensions-4.15.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/transformers-4.49.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/requests-2.32.5-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/spacy_alignments-0.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/packaging-26.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/spacy-3.8.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/python_crfsuite-0.9.12-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nltk-3.9.2-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/hazm-0.11.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/filelock-3.21.2-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/__results__.html\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/typing_inspection-0.4.2-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/rich-14.3.2-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/networkx-3.6.1-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/annotated_types-0.7.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/jinja2-3.1.6-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/annotated_doc-0.0.4-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/input_requirements.txt\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/typer-0.23.1-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/pydantic-2.12.5-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/idna-3.11-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/threadpoolctl-3.6.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/tqdm-4.67.3-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/preshed-3.0.12-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/blis-1.3.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/smart_open-7.5.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/pygments-2.19.2-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/__script__.ipynb\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/murmurhash-1.0.15-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/markdown_it_py-4.0.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/srsly-2.5.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/cuda_pathfinder-1.3.4-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/catalogue-2.0.10-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/urllib3-2.6.3-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/thinc-8.3.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/__output__.json\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/spacy_legacy-3.0.12-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/weasel-0.4.3-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/wrapt-2.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/cloudpathlib-0.23.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/sympy-1.14.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/click-8.3.1-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/mdurl-0.1.2-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/joblib-1.5.3-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/wasabi-1.1.3-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/fsspec-2026.2.0-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/spacy_transformers-1.3.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/install_requirements.sh\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/typer_slim-0.23.1-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/flashtext-2.7.tar.gz\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/confection-0.1.5-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/certifi-2026.1.4-py3-none-any.whl\n",
      "/kaggle/input/pm-109376216-at-02-13-2026-10-41-16/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6850059a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T10:45:05.123155Z",
     "iopub.status.busy": "2026-02-13T10:45:05.122351Z",
     "iopub.status.idle": "2026-02-13T10:45:44.694314Z",
     "shell.execute_reply": "2026-02-13T10:45:44.693161Z"
    },
    "papermill": {
     "duration": 39.580638,
     "end_time": "2026-02-13T10:45:44.696713",
     "exception": false,
     "start_time": "2026-02-13T10:45:05.116075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "PyTorch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  FULL PIPELINE: LSTM for Persian Question Ambiguity Detection\n",
    "# ============================================================\n",
    "#  Stage 1: Preprocessing V2 (train + test)\n",
    "#  Stage 2: Vocabulary & Dataset\n",
    "#  Stage 3: LSTM Model Definition\n",
    "#  Stage 4: Training with dev (train-as-dev) monitoring\n",
    "#  Stage 5: Final test evaluation & model saving\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "from hazm import Normalizer, word_tokenize\n",
    "\n",
    "# ============================================================\n",
    "#  CONFIG\n",
    "# ============================================================\n",
    "class Config:\n",
    "    # Paths\n",
    "    TRAIN_PATH = \"/kaggle/input/datasets/aabdollahii/university-questions/train.json\"\n",
    "    TEST_PATH = \"/kaggle/input/datasets/aabdollahii/university-questions/test.json\"\n",
    "    SAVE_DIR = \"/kaggle/working/\"\n",
    "    \n",
    "    # Preprocessing\n",
    "    MAX_LEN = 64           # max tokens per question (will verify from data)\n",
    "    MIN_FREQ = 2           # min word frequency to include in vocab\n",
    "    \n",
    "    # Model\n",
    "    EMBED_DIM = 128\n",
    "    HIDDEN_DIM = 128\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "    BIDIRECTIONAL = True\n",
    "    \n",
    "    # Training\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "    LR = 1e-3\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    PATIENCE = 7           # early stopping patience\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Reproducibility\n",
    "    SEED = 42\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(cfg.SEED)\n",
    "np.random.seed(cfg.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(cfg.SEED)\n",
    "\n",
    "print(f\"Device: {cfg.DEVICE}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc846c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T10:45:44.704910Z",
     "iopub.status.busy": "2026-02-13T10:45:44.704172Z",
     "iopub.status.idle": "2026-02-13T10:59:45.502804Z",
     "shell.execute_reply": "2026-02-13T10:59:45.501420Z"
    },
    "papermill": {
     "duration": 840.808281,
     "end_time": "2026-02-13T10:59:45.507847",
     "exception": false,
     "start_time": "2026-02-13T10:45:44.699566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  STAGE 1: PREPROCESSING V2\n",
      "=================================================================\n",
      "Loading train.json ...\n",
      "  Train shape: (900, 4)\n",
      "  Label distribution:\n",
      "is_ambiguous\n",
      "0    450\n",
      "1    450\n",
      "\n",
      "Loading test.json ...\n",
      "  Test shape: (100, 4)\n",
      "  Test label distribution:\n",
      "is_ambiguous\n",
      "0    50\n",
      "1    50\n",
      "\n",
      "Normalizing train questions ...\n",
      "Normalizing test questions ...\n",
      "Tokenizing train ...\n",
      "Tokenizing test ...\n",
      "\n",
      "--- Train Samples ---\n",
      "  [0] حداقل نمره قبولی در هر درس برای دانشجویان مقطع کارشناسی چند است؟\n",
      "       → ['حداقل', 'نمره', 'قبولی', 'در', 'هر', 'درس', 'برای', 'دانشجویان', 'مقطع', 'کارشناسی', 'چند', 'است', '؟'] ...\n",
      "\n",
      "  [0] حداکثر سنوات مجاز تحصیل در دوره کارشناسی پیوسته چند نیمسال است؟\n",
      "       → ['حداکثر', 'سنوات', 'مجاز', 'تحصیل', 'در', 'دوره', 'کارشناسی', 'پیوسته', 'چند', 'نیمسال', 'است', '؟'] ...\n",
      "\n",
      "  [0] آیا دانشجوی کارشناسی می‌تواند با معدل بالای ۱۷، بیش از ۲۰ واحد در ترم بعد اخذ کند؟\n",
      "       → ['آیا', 'دانشجوی', 'کارشناسی', 'می', 'تواند', 'با', 'معدل', 'بالای', '۱۷', '،', 'بیش', 'از', '۲۰', 'واحد', 'در'] ...\n",
      "\n",
      "  [0] دانشجوی کارشناسی ارشد حداکثر چند نیمسال می‌تواند از مرخصی تحصیلی استفاده کند؟\n",
      "       → ['دانشجوی', 'کارشناسی', 'ارشد', 'حداکثر', 'چند', 'نیمسال', 'می', 'تواند', 'از', 'مرخصی', 'تحصیلی', 'استفاده', 'کند', '؟'] ...\n",
      "\n",
      "  [0] آخرین مهلت برای حذف تک‌درس (حذف اضطراری) در طول نیمسال چه زمانی است؟\n",
      "       → ['آخرین', 'مهلت', 'برای', 'حذف', 'تک', 'درس', 'حذف', 'اضطراری', 'در', 'طول', 'نیمسال', 'چه', 'زمانی', 'است', '؟'] ...\n",
      "\n",
      "Token length stats (train):\n",
      "  Mean:   10.2\n",
      "  Median: 10.0\n",
      "  95th %: 17\n",
      "  99th %: 22\n",
      "  Max:    25\n",
      "\n",
      "   Updating MAX_LEN: 64 → 19\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  STAGE 1: PREPROCESSING V2\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  STAGE 1: PREPROCESSING V2\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "formal_normalizer = Normalizer()\n",
    "\n",
    "def normalize_v2(text):\n",
    "    \"\"\"\n",
    "    V2 normalization pipeline — safe version (no InformalNormalizer).\n",
    "    1. Hazm formal normalization (handles ی/ک, spacing, etc.)\n",
    "    2. Arabic char normalization\n",
    "    3. Clean punctuation/extra whitespace\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    # Step 1: Hazm formal normalization\n",
    "    text = formal_normalizer.normalize(text)\n",
    "    \n",
    "    # Step 2: Additional Arabic → Persian char normalization\n",
    "    text = text.replace(\"ي\", \"ی\").replace(\"ك\", \"ک\")\n",
    "    text = text.replace(\"ؤ\", \"و\").replace(\"إ\", \"ا\").replace(\"أ\", \"ا\")\n",
    "    text = text.replace(\"ة\", \"ه\")\n",
    "    \n",
    "    # Step 3: Normalize various dashes and special chars\n",
    "    text = re.sub(r'[ـ]+', '', text)              # remove kashida (tatweel)\n",
    "    text = re.sub(r'[‌]+', ' ', text)              # replace ZWNJ with space (hazm handles most)\n",
    "    \n",
    "    # Step 4: Keep Persian/Arabic letters, digits, basic punctuation, spaces\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\u0750-\\u077F\\uFB50-\\uFDFF\\uFE70-\\uFEFF'\n",
    "                  r'a-zA-Z0-9۰-۹٠-٩\\s\\.\\?\\!،؛]', ' ', text)\n",
    "    \n",
    "    # Step 5: Clean extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Tokenize using Hazm word_tokenize after normalization.\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    return word_tokenize(text)\n",
    "\n",
    "\n",
    "# --- Load Data ---\n",
    "print(\"Loading train.json ...\")\n",
    "with open(cfg.TRAIN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "df_train = pd.DataFrame(train_data)\n",
    "print(f\"  Train shape: {df_train.shape}\")\n",
    "print(f\"  Label distribution:\\n{df_train['is_ambiguous'].value_counts().to_string()}\")\n",
    "\n",
    "print(\"\\nLoading test.json ...\")\n",
    "with open(cfg.TEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "print(f\"  Test shape: {df_test.shape}\")\n",
    "has_test_labels = \"is_ambiguous\" in df_test.columns\n",
    "if has_test_labels:\n",
    "    print(f\"  Test label distribution:\\n{df_test['is_ambiguous'].value_counts().to_string()}\")\n",
    "\n",
    "# --- Apply Normalization ---\n",
    "print(\"\\nNormalizing train questions ...\")\n",
    "df_train[\"norm_text\"] = df_train[\"question\"].apply(normalize_v2)\n",
    "print(\"Normalizing test questions ...\")\n",
    "df_test[\"norm_text\"] = df_test[\"question\"].apply(normalize_v2)\n",
    "\n",
    "# --- Tokenize ---\n",
    "print(\"Tokenizing train ...\")\n",
    "df_train[\"tokens\"] = df_train[\"norm_text\"].apply(tokenize_text)\n",
    "print(\"Tokenizing test ...\")\n",
    "df_test[\"tokens\"] = df_test[\"norm_text\"].apply(tokenize_text)\n",
    "\n",
    "# --- Show Samples ---\n",
    "print(\"\\n--- Train Samples ---\")\n",
    "for i in range(5):\n",
    "    print(f\"  [{df_train['is_ambiguous'].iloc[i]}] {df_train['question'].iloc[i]}\")\n",
    "    print(f\"       → {df_train['tokens'].iloc[i][:15]} ...\")\n",
    "    print()\n",
    "\n",
    "# --- Sequence Length Analysis ---\n",
    "train_lengths = df_train[\"tokens\"].apply(len)\n",
    "print(f\"Token length stats (train):\")\n",
    "print(f\"  Mean:   {train_lengths.mean():.1f}\")\n",
    "print(f\"  Median: {train_lengths.median():.1f}\")\n",
    "print(f\"  95th %: {train_lengths.quantile(0.95):.0f}\")\n",
    "print(f\"  99th %: {train_lengths.quantile(0.99):.0f}\")\n",
    "print(f\"  Max:    {train_lengths.max()}\")\n",
    "\n",
    "# Update MAX_LEN based on data (cover 95th percentile)\n",
    "suggested_max_len = int(train_lengths.quantile(0.95)) + 2\n",
    "if suggested_max_len != cfg.MAX_LEN:\n",
    "    print(f\"\\n   Updating MAX_LEN: {cfg.MAX_LEN} → {suggested_max_len}\")\n",
    "    cfg.MAX_LEN = suggested_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967155b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T10:59:45.517842Z",
     "iopub.status.busy": "2026-02-13T10:59:45.516792Z",
     "iopub.status.idle": "2026-02-13T10:59:45.589480Z",
     "shell.execute_reply": "2026-02-13T10:59:45.588055Z"
    },
    "papermill": {
     "duration": 0.08092,
     "end_time": "2026-02-13T10:59:45.592001",
     "exception": false,
     "start_time": "2026-02-13T10:59:45.511081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  STAGE 2: VOCABULARY & DATASET\n",
      "=================================================================\n",
      "Total unique words in train: 1155\n",
      "Vocab size (min_freq=2): 652\n",
      "  (including <PAD> and <UNK>)\n",
      "Test OOV rate: 90/1026 = 8.8%\n",
      "\n",
      "DataLoaders ready:\n",
      "  Train: 900 samples, 29 batches\n",
      "  Dev:   900 samples (= train, for debugging)\n",
      "  Test:  100 samples\n",
      "\n",
      "Class balance: neg=450, pos=450\n",
      "  pos_weight for BCEWithLogitsLoss: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  STAGE 2: VOCABULARY & DATASET\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  STAGE 2: VOCABULARY & DATASET\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# --- Build Vocabulary (from TRAINING data only) ---\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "word_counts = Counter()\n",
    "for tokens in df_train[\"tokens\"]:\n",
    "    word_counts.update(tokens)\n",
    "\n",
    "print(f\"Total unique words in train: {len(word_counts)}\")\n",
    "\n",
    "# Filter by min frequency\n",
    "vocab_words = [w for w, c in word_counts.items() if c >= cfg.MIN_FREQ]\n",
    "vocab_words.sort()  # deterministic order\n",
    "\n",
    "word2idx = {PAD_TOKEN: PAD_IDX, UNK_TOKEN: UNK_IDX}\n",
    "for w in vocab_words:\n",
    "    word2idx[w] = len(word2idx)\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "print(f\"Vocab size (min_freq={cfg.MIN_FREQ}): {vocab_size}\")\n",
    "print(f\"  (including <PAD> and <UNK>)\")\n",
    "\n",
    "# Check OOV rate on test\n",
    "if len(df_test) > 0:\n",
    "    test_tokens_all = [t for tokens in df_test[\"tokens\"] for t in tokens]\n",
    "    oov_count = sum(1 for t in test_tokens_all if t not in word2idx)\n",
    "    print(f\"Test OOV rate: {oov_count}/{len(test_tokens_all)} = \"\n",
    "          f\"{oov_count/max(len(test_tokens_all),1)*100:.1f}%\")\n",
    "\n",
    "\n",
    "def encode_tokens(tokens, word2idx, max_len):\n",
    "    \"\"\"Convert token list to padded index array.\"\"\"\n",
    "    ids = [word2idx.get(t, UNK_IDX) for t in tokens[:max_len]]\n",
    "    length = len(ids)\n",
    "    # Pad\n",
    "    ids = ids + [PAD_IDX] * (max_len - length)\n",
    "    return ids, length\n",
    "\n",
    "\n",
    "# --- PyTorch Dataset ---\n",
    "class QuestionDataset(Dataset):\n",
    "    def __init__(self, tokens_list, labels, word2idx, max_len):\n",
    "        self.tokens_list = tokens_list\n",
    "        self.labels = labels\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokens_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        ids, length = encode_tokens(tokens, self.word2idx, self.max_len)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"length\": torch.tensor(length, dtype=torch.long),\n",
    "            \"label\": torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- Prepare splits ---\n",
    "# Full training set\n",
    "train_tokens = df_train[\"tokens\"].tolist()\n",
    "train_labels = df_train[\"is_ambiguous\"].values.astype(int)\n",
    "\n",
    "# Test set\n",
    "test_tokens = df_test[\"tokens\"].tolist()\n",
    "if has_test_labels:\n",
    "    test_labels = df_test[\"is_ambiguous\"].values.astype(int)\n",
    "else:\n",
    "    test_labels = np.zeros(len(df_test), dtype=int)  # placeholder\n",
    "\n",
    "# Dev set = train set (as per your request, for debugging)\n",
    "dev_tokens = train_tokens\n",
    "dev_labels = train_labels\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = QuestionDataset(train_tokens, train_labels, word2idx, cfg.MAX_LEN)\n",
    "dev_dataset   = QuestionDataset(dev_tokens, dev_labels, word2idx, cfg.MAX_LEN)\n",
    "test_dataset  = QuestionDataset(test_tokens, test_labels, word2idx, cfg.MAX_LEN)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoaders ready:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples, {len(train_loader)} batches\")\n",
    "print(f\"  Dev:   {len(dev_dataset)} samples (= train, for debugging)\")\n",
    "print(f\"  Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# --- Compute class weights ---\n",
    "n_pos = train_labels.sum()\n",
    "n_neg = len(train_labels) - n_pos\n",
    "pos_weight = torch.tensor([n_neg / max(n_pos, 1)], dtype=torch.float).to(cfg.DEVICE)\n",
    "print(f\"\\nClass balance: neg={n_neg}, pos={n_pos}\")\n",
    "print(f\"  pos_weight for BCEWithLogitsLoss: {pos_weight.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a4e63d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T10:59:45.604650Z",
     "iopub.status.busy": "2026-02-13T10:59:45.601955Z",
     "iopub.status.idle": "2026-02-13T10:59:45.685252Z",
     "shell.execute_reply": "2026-02-13T10:59:45.683996Z"
    },
    "papermill": {
     "duration": 0.092676,
     "end_time": "2026-02-13T10:59:45.689135",
     "exception": false,
     "start_time": "2026-02-13T10:59:45.596459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  STAGE 3: LSTM MODEL DEFINITION\n",
      "=================================================================\n",
      "\n",
      "Model Architecture:\n",
      "LSTMClassifier(\n",
      "  (embedding): Embedding(652, 128, padding_idx=0)\n",
      "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters:     940,033\n",
      "Trainable parameters: 940,033\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  STAGE 3: LSTM MODEL\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  STAGE 3: LSTM MODEL DEFINITION\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers,\n",
    "                 dropout, bidirectional, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embed_dim, padding_idx=pad_idx\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # If bidirectional, hidden output is 2 * hidden_dim\n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        \n",
    "        # Attention-like pooling: combine last hidden state + max pool + mean pool\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim * 3, lstm_output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_output_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, lengths):\n",
    "        # input_ids: (batch, max_len)\n",
    "        # lengths:   (batch,)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input_ids))\n",
    "        # embedded: (batch, max_len, embed_dim)\n",
    "        \n",
    "        # Pack padded sequences for efficient LSTM\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, lengths.cpu().clamp(min=1),\n",
    "            batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        lstm_out, (hidden, cell) = self.lstm(packed)\n",
    "        \n",
    "        # Unpack\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            lstm_out, batch_first=True, total_length=input_ids.size(1)\n",
    "        )\n",
    "        # lstm_out: (batch, max_len, lstm_output_dim)\n",
    "        \n",
    "        # Create mask for padded positions\n",
    "        mask = (input_ids != PAD_IDX).unsqueeze(-1).float()\n",
    "        # mask: (batch, max_len, 1)\n",
    "        \n",
    "        # --- Pooling strategies ---\n",
    "        # 1. Last hidden state (concat forward + backward for bidirectional)\n",
    "        if self.lstm.bidirectional:\n",
    "            # hidden: (num_layers * 2, batch, hidden_dim)\n",
    "            last_hidden = torch.cat(\n",
    "                [hidden[-2], hidden[-1]], dim=-1\n",
    "            )  # (batch, hidden_dim * 2)\n",
    "        else:\n",
    "            last_hidden = hidden[-1]  # (batch, hidden_dim)\n",
    "        \n",
    "        # 2. Max pooling (masked)\n",
    "        lstm_out_masked = lstm_out * mask + (1 - mask) * (-1e9)\n",
    "        max_pool, _ = lstm_out_masked.max(dim=1)  # (batch, lstm_output_dim)\n",
    "        \n",
    "        # 3. Mean pooling (masked)\n",
    "        sum_pool = (lstm_out * mask).sum(dim=1)  # (batch, lstm_output_dim)\n",
    "        lengths_expanded = lengths.unsqueeze(-1).float().clamp(min=1).to(sum_pool.device)\n",
    "        mean_pool = sum_pool / lengths_expanded\n",
    "        \n",
    "        # Concatenate all three\n",
    "        combined = torch.cat([last_hidden, max_pool, mean_pool], dim=-1)\n",
    "        \n",
    "        logits = self.fc(self.dropout(combined)).squeeze(-1)\n",
    "        # logits: (batch,)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Instantiate\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=cfg.EMBED_DIM,\n",
    "    hidden_dim=cfg.HIDDEN_DIM,\n",
    "    num_layers=cfg.NUM_LAYERS,\n",
    "    dropout=cfg.DROPOUT,\n",
    "    bidirectional=cfg.BIDIRECTIONAL,\n",
    "    pad_idx=PAD_IDX\n",
    ").to(cfg.DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters:     {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1f20cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T10:59:45.699586Z",
     "iopub.status.busy": "2026-02-13T10:59:45.699114Z",
     "iopub.status.idle": "2026-02-13T11:00:35.668947Z",
     "shell.execute_reply": "2026-02-13T11:00:35.667650Z"
    },
    "papermill": {
     "duration": 49.977358,
     "end_time": "2026-02-13T11:00:35.671261",
     "exception": false,
     "start_time": "2026-02-13T10:59:45.693903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  STAGE 4: TRAINING\n",
      "=================================================================\n",
      "\n",
      "Starting training for 10 epochs ...\n",
      "Epoch | Train Loss |   Dev Loss |   Dev F1 |  Dev Acc |         LR | Status\n",
      "-------------------------------------------------------------------------------------\n",
      "    1 |     0.5566 |     0.4265 |   0.8229 |   0.8256 |   0.001000 | ★ BEST\n",
      "    2 |     0.3643 |     0.2443 |   0.8977 |   0.8978 |   0.001000 | ★ BEST\n",
      "    3 |     0.2690 |     0.1780 |   0.9378 |   0.9378 |   0.001000 | ★ BEST\n",
      "    4 |     0.2146 |     0.1137 |   0.9600 |   0.9600 |   0.001000 | ★ BEST\n",
      "    5 |     0.1845 |     0.0846 |   0.9744 |   0.9744 |   0.001000 | ★ BEST\n",
      "    6 |     0.1314 |     0.0571 |   0.9867 |   0.9867 |   0.001000 | ★ BEST\n",
      "    7 |     0.0950 |     0.0328 |   0.9878 |   0.9878 |   0.001000 | ★ BEST\n",
      "    8 |     0.0921 |     0.0221 |   0.9922 |   0.9922 |   0.001000 | ★ BEST\n",
      "    9 |     0.0709 |     0.0165 |   0.9956 |   0.9956 |   0.001000 | ★ BEST\n",
      "   10 |     0.0717 |     0.0161 |   0.9944 |   0.9944 |   0.001000 | \n",
      "\n",
      "  Best Dev F1-Macro: 0.9956\n",
      "\n",
      "--- Dev Set Report (Train-as-Dev, Best Checkpoint) ---\n",
      "\n",
      "Dev F1-Macro:  0.9956\n",
      "Dev Accuracy:  0.9956\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Ambiguous     0.9934    0.9978    0.9956       450\n",
      "    Ambiguous     0.9978    0.9933    0.9955       450\n",
      "\n",
      "     accuracy                         0.9956       900\n",
      "    macro avg     0.9956    0.9956    0.9956       900\n",
      " weighted avg     0.9956    0.9956    0.9956       900\n",
      "\n",
      "Confusion Matrix:\n",
      "                  Pred_NotAmb  Pred_Amb\n",
      "  True_NotAmb          449            1\n",
      "  True_Amb               3          447\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  STAGE 4: TRAINING WITH DEV MONITORING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  STAGE 4: TRAINING\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY\n",
    ")\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model on a dataloader. Returns loss, preds, labels.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            lengths = batch[\"length\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            \n",
    "            logits = model(input_ids, lengths)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "            \n",
    "            preds = (torch.sigmoid(logits) >= 0.5).long().cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy().astype(int))\n",
    "    \n",
    "    avg_loss = total_loss / max(n_batches, 1)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, f1, acc, all_preds, all_labels\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "best_dev_f1 = 0.0\n",
    "patience_counter = 0\n",
    "history = {\"train_loss\": [], \"dev_loss\": [], \"dev_f1\": [], \"dev_acc\": [], \"lr\": []}\n",
    "\n",
    "print(f\"\\nStarting training for {cfg.EPOCHS} epochs ...\")\n",
    "print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Dev Loss':>10} | \"\n",
    "      f\"{'Dev F1':>8} | {'Dev Acc':>8} | {'LR':>10} | {'Status'}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    n_train_batches = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(cfg.DEVICE)\n",
    "        lengths = batch[\"length\"].to(cfg.DEVICE)\n",
    "        labels = batch[\"label\"].to(cfg.DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, lengths)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_sum += loss.item()\n",
    "        n_train_batches += 1\n",
    "    \n",
    "    avg_train_loss = train_loss_sum / max(n_train_batches, 1)\n",
    "    \n",
    "    # --- Evaluate on dev (= train, for debugging) ---\n",
    "    dev_loss, dev_f1, dev_acc, dev_preds, dev_labels = evaluate(\n",
    "        model, dev_loader, criterion, cfg.DEVICE\n",
    "    )\n",
    "    \n",
    "    # --- LR scheduler ---\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step(dev_f1)\n",
    "    \n",
    "    # --- Track history ---\n",
    "    history[\"train_loss\"].append(avg_train_loss)\n",
    "    history[\"dev_loss\"].append(dev_loss)\n",
    "    history[\"dev_f1\"].append(dev_f1)\n",
    "    history[\"dev_acc\"].append(dev_acc)\n",
    "    history[\"lr\"].append(current_lr)\n",
    "    \n",
    "    # --- Early stopping & checkpointing ---\n",
    "    status = \"\"\n",
    "    if dev_f1 > best_dev_f1:\n",
    "        best_dev_f1 = dev_f1\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), os.path.join(cfg.SAVE_DIR, \"best_lstm.pt\"))\n",
    "        status = \"★ BEST\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= cfg.PATIENCE:\n",
    "            status = \" STOP\"\n",
    "        \n",
    "    print(f\"{epoch:>5} | {avg_train_loss:>10.4f} | {dev_loss:>10.4f} | \"\n",
    "          f\"{dev_f1:>8.4f} | {dev_acc:>8.4f} | {current_lr:>10.6f} | {status}\")\n",
    "    \n",
    "    if patience_counter >= cfg.PATIENCE:\n",
    "        print(f\"\\n  Early stopping triggered at epoch {epoch} (patience={cfg.PATIENCE})\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n  Best Dev F1-Macro: {best_dev_f1:.4f}\")\n",
    "\n",
    "# --- Dev set detailed report (at best checkpoint) ---\n",
    "print(\"\\n--- Dev Set Report (Train-as-Dev, Best Checkpoint) ---\")\n",
    "model.load_state_dict(torch.load(os.path.join(cfg.SAVE_DIR, \"best_lstm.pt\")))\n",
    "\n",
    "dev_loss, dev_f1, dev_acc, dev_preds, dev_labels = evaluate(\n",
    "    model, dev_loader, criterion, cfg.DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\nDev F1-Macro:  {dev_f1:.4f}\")\n",
    "print(f\"Dev Accuracy:  {dev_acc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    dev_labels, dev_preds,\n",
    "    target_names=[\"Not Ambiguous\", \"Ambiguous\"],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(dev_labels, dev_preds)\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"                  Pred_NotAmb  Pred_Amb\")\n",
    "print(f\"  True_NotAmb     {cm[0][0]:>8}     {cm[0][1]:>8}\")\n",
    "print(f\"  True_Amb        {cm[1][0]:>8}     {cm[1][1]:>8}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb7bf51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:00:35.684236Z",
     "iopub.status.busy": "2026-02-13T11:00:35.683196Z",
     "iopub.status.idle": "2026-02-13T11:00:35.814087Z",
     "shell.execute_reply": "2026-02-13T11:00:35.812183Z"
    },
    "papermill": {
     "duration": 0.140383,
     "end_time": "2026-02-13T11:00:35.816505",
     "exception": false,
     "start_time": "2026-02-13T11:00:35.676122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  STAGE 5: FINAL TEST EVALUATION & MODEL SAVING\n",
      "=================================================================\n",
      "\n",
      "========================================\n",
      "  FINAL TEST RESULTS\n",
      "========================================\n",
      "  Test F1-Macro:  0.9000\n",
      "  Test Accuracy:  0.9000\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Ambiguous     0.9000    0.9000    0.9000        50\n",
      "    Ambiguous     0.9000    0.9000    0.9000        50\n",
      "\n",
      "     accuracy                         0.9000       100\n",
      "    macro avg     0.9000    0.9000    0.9000       100\n",
      " weighted avg     0.9000    0.9000    0.9000       100\n",
      "\n",
      "Confusion Matrix:\n",
      "                  Pred_NotAmb  Pred_Amb\n",
      "  True_NotAmb           45            5\n",
      "  True_Amb               5           45\n",
      "\n",
      "--- Saving Model Artifacts ---\n",
      "   Vocabulary saved: /kaggle/working/vocab.pkl\n",
      "   Config saved: /kaggle/working/config.pkl\n",
      "   Training history saved: /kaggle/working/training_history.pkl\n",
      "   Model weights: /kaggle/working/best_lstm.pt\n",
      "   Predictions: lstm_test_predictions.csv\n",
      "   Submission: submission.csv\n",
      "\n",
      "=================================================================\n",
      "  PIPELINE COMPLETE — SUMMARY\n",
      "=================================================================\n",
      "  Model:          BiLSTM (2-layer, hidden=128)\n",
      "  Vocab size:     652\n",
      "  Max seq length: 19\n",
      "  Best Dev F1:    0.9956\n",
      "  Test F1-Macro:  0.9000\n",
      "  Test Accuracy:  0.9000\n",
      "  Saved files:    best_lstm.pt, vocab.pkl, config.pkl, training_history.pkl, submission.csv\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  STAGE 5: FINAL TEST EVALUATION & SAVE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  STAGE 5: FINAL TEST EVALUATION & MODEL SAVING\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# --- Test evaluation ---\n",
    "test_loss, test_f1, test_acc, test_preds, test_labels_arr = evaluate(\n",
    "    model, test_loader, criterion, cfg.DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(f\"  FINAL TEST RESULTS\")\n",
    "print(f\"{'='*40}\")\n",
    "\n",
    "if has_test_labels:\n",
    "    print(f\"  Test F1-Macro:  {test_f1:.4f}\")\n",
    "    print(f\"  Test Accuracy:  {test_acc:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        test_labels_arr, test_preds,\n",
    "        target_names=[\"Not Ambiguous\", \"Ambiguous\"],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    cm_test = confusion_matrix(test_labels_arr, test_preds)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(f\"                  Pred_NotAmb  Pred_Amb\")\n",
    "    print(f\"  True_NotAmb     {cm_test[0][0]:>8}     {cm_test[0][1]:>8}\")\n",
    "    print(f\"  True_Amb        {cm_test[1][0]:>8}     {cm_test[1][1]:>8}\")\n",
    "else:\n",
    "    print(f\"  No test labels available — predictions saved only.\")\n",
    "    print(f\"  Prediction distribution:\")\n",
    "    print(f\"    Not Ambiguous (0): {(test_preds == 0).sum()}\")\n",
    "    print(f\"    Ambiguous (1):     {(test_preds == 1).sum()}\")\n",
    "\n",
    "# --- Save predictions ---\n",
    "df_test[\"predicted_label\"] = test_preds\n",
    "\n",
    "output_cols = [\"id\", \"question\", \"norm_text\", \"predicted_label\"]\n",
    "if has_test_labels:\n",
    "    output_cols.insert(3, \"is_ambiguous\")\n",
    "df_test[output_cols].to_csv(\n",
    "    os.path.join(cfg.SAVE_DIR, \"lstm_test_predictions.csv\"),\n",
    "    index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "# Submission file\n",
    "submission = df_test[[\"id\", \"predicted_label\"]].copy()\n",
    "submission.columns = [\"id\", \"is_ambiguous\"]\n",
    "submission.to_csv(os.path.join(cfg.SAVE_DIR, \"submission.csv\"), index=False)\n",
    "\n",
    "# --- Save model artifacts ---\n",
    "# 1. Model weights (already saved as best_lstm.pt)\n",
    "print(f\"\\n--- Saving Model Artifacts ---\")\n",
    "\n",
    "# 2. Vocabulary\n",
    "vocab_path = os.path.join(cfg.SAVE_DIR, \"vocab.pkl\")\n",
    "with open(vocab_path, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"word2idx\": word2idx,\n",
    "        \"idx2word\": idx2word,\n",
    "        \"vocab_size\": vocab_size\n",
    "    }, f)\n",
    "print(f\"   Vocabulary saved: {vocab_path}\")\n",
    "\n",
    "# 3. Config\n",
    "config_dict = {\n",
    "    \"max_len\": cfg.MAX_LEN,\n",
    "    \"embed_dim\": cfg.EMBED_DIM,\n",
    "    \"hidden_dim\": cfg.HIDDEN_DIM,\n",
    "    \"num_layers\": cfg.NUM_LAYERS,\n",
    "    \"dropout\": cfg.DROPOUT,\n",
    "    \"bidirectional\": cfg.BIDIRECTIONAL,\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"pad_idx\": PAD_IDX,\n",
    "    \"best_dev_f1\": best_dev_f1,\n",
    "}\n",
    "if has_test_labels:\n",
    "    config_dict[\"test_f1\"] = test_f1\n",
    "    config_dict[\"test_acc\"] = test_acc\n",
    "\n",
    "config_path = os.path.join(cfg.SAVE_DIR, \"config.pkl\")\n",
    "with open(config_path, \"wb\") as f:\n",
    "    pickle.dump(config_dict, f)\n",
    "print(f\"   Config saved: {config_path}\")\n",
    "\n",
    "# 4. Training history\n",
    "history_path = os.path.join(cfg.SAVE_DIR, \"training_history.pkl\")\n",
    "with open(history_path, \"wb\") as f:\n",
    "    pickle.dump(history, f)\n",
    "print(f\"   Training history saved: {history_path}\")\n",
    "\n",
    "print(f\"   Model weights: {os.path.join(cfg.SAVE_DIR, 'best_lstm.pt')}\")\n",
    "print(f\"   Predictions: lstm_test_predictions.csv\")\n",
    "print(f\"   Submission: submission.csv\")\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  PIPELINE COMPLETE — SUMMARY\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"  Model:          BiLSTM (2-layer, hidden={cfg.HIDDEN_DIM})\")\n",
    "print(f\"  Vocab size:     {vocab_size:,}\")\n",
    "print(f\"  Max seq length: {cfg.MAX_LEN}\")\n",
    "print(f\"  Best Dev F1:    {best_dev_f1:.4f}\")\n",
    "if has_test_labels:\n",
    "    print(f\"  Test F1-Macro:  {test_f1:.4f}\")\n",
    "    print(f\"  Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"  Saved files:    best_lstm.pt, vocab.pkl, config.pkl, \"\n",
    "      f\"training_history.pkl, submission.csv\")\n",
    "print(\"=\" * 65)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9478698,
     "sourceId": 14821512,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 939.130796,
   "end_time": "2026-02-13T11:00:38.866386",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-13T10:44:59.735590",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
